# ğŸ“„ RAG Question Answering System

This project is a **Retrieval-Augmented Generation (RAG)** based Question Answering system built using **FastAPI, FAISS, Sentence Transformers, and FLAN-T5**.

The application allows users to upload documents and ask questions based strictly on the document content.

---

## ğŸš€ Features

- ğŸ“‚ Upload **PDF or TXT** documents  
- âœ‚ï¸ Automatic **text chunking**  
- ğŸ§  Embedding generation using **Sentence Transformers**  
- ğŸ” Semantic search with **FAISS vector database**  
- ğŸ¤– Answer generation using a **FLAN-T5 LLM**  
- ğŸ“š Source chunk display for transparency  

---

## ğŸ—ï¸ System Architecture

The pipeline follows these steps:

1. Document Upload  
2. Text Extraction  
3. Text Cleaning  
4. Chunking  
5. Embedding Generation  
6. Vector Storage (FAISS)  
7. Question Embedding  
8. Similarity Search  
9. LLM Answer Generation  

This ensures answers are grounded in the uploaded document.
## ğŸŸ¢ Tech Stack

The project uses the following technologies:

- **FastAPI** â€“ Backend API framework  
- **HTML + Tailwind CSS** â€“ Frontend user interface  
- **Sentence Transformers** â€“ For generating text embeddings  
- **FAISS** â€“ Vector database for similarity search  
- **FLAN-T5** â€“ Language model for answer generation  
- **PyPDF2** â€“ For extracting text from PDF documents  


---

## â–¶ Run Locally

```bash
pip install -r requirements.txt
uvicorn app.main:app --reload
```

Now open your browser and go to:

ğŸ‘‰ **http://127.0.0.1:8000**

---

## ğŸ–¥ï¸ How to Use the Application

### 1ï¸âƒ£ Upload a Document

- Click **Choose File**
- Select a **PDF or TXT** file
- Click **Upload**

The system will:
- Extract text from the document  
- Split it into chunks  
- Generate embeddings  
- Store them in the FAISS vector database  

â³ Wait until you see:  
**â€œProcessing completed. You can now ask questions.â€**

---

### 2ï¸âƒ£ Ask Questions

- Enter a question related to the uploaded document  

**Example:**
```text
What is ClaSum?
```

- Click **Get Answer**

---

## âš™ï¸ How Answers Are Generated

When a question is asked:

1. The question is converted into an embedding  
2. FAISS retrieves the most relevant document chunks  
3. These chunks are sent as context to the LLM  
4. The LLM generates an answer **based only on retrieved content**

This reduces hallucinations and keeps answers document-grounded.
